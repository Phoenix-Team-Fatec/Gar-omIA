{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyTelegramBotAPI\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install torch\n",
        "!pip install gtts\n",
        "!pip install spacy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh4Ua1VK-95D",
        "outputId": "7b2c707e-9272-4452-f8bb-9d3c288f6333",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyTelegramBotAPI\n",
            "  Downloading pytelegrambotapi-4.24.0-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyTelegramBotAPI) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2024.8.30)\n",
            "Downloading pytelegrambotapi-4.24.0-py3-none-any.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.0/265.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyTelegramBotAPI\n",
            "Successfully installed pyTelegramBotAPI-4.24.0\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-8bhvwk0c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-8bhvwk0c\n",
            "  Resolved https://github.com/openai/whisper.git to commit 173ff7dd1d9fb1c4fddea0d41d704cfefeb8908c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803557 sha256=09198e02298c8522a0616deead24dbe2e95f26c90a851ba625b448b1e1b33f2a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k4f624mk/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.4\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LUu5L5r-zZw",
        "outputId": "2ce75959-6dd5-453b-893e-e1cf9f4b17d1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.5\n",
            "11.5\n",
            "10.5\n",
            "10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "import telebot\n",
        "import whisper\n",
        "import os\n",
        "from gtts import gTTS\n",
        "\n",
        "\n",
        "# Iniciando o bot e o modelo Whisper\n",
        "bot = telebot.TeleBot(\"SeuToken")\n",
        "\n",
        "\n",
        "# Inicializando o modelo spaCy e Whisper\n",
        "nlp = spacy.blank(\"pt\")  # Carrega um modelo básico de português\n",
        "model = whisper.load_model(\"base\")  # Modelo Whisper para transcrição de áudio\n",
        "\n",
        "# Configurando o diretório para salvar os áudios recebidos\n",
        "AUDIO_DIR = \"/content/audio_files/\"\n",
        "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# Cardápio com itens disponíveis, seus tipos e preços\n",
        "menu = {\n",
        "    1: {\"nome\": \"Arroz\", \"tipo\": \"Prato Principal\", \"valor\": 12.00},\n",
        "    2: {\"nome\": \"Frango\", \"tipo\": \"Prato Principal\", \"valor\": 15.00},\n",
        "    3: {\"nome\": \"Salada\", \"tipo\": \"Prato Principal\", \"valor\": 10.00},\n",
        "    4: {\"nome\": \"Lasanha\", \"tipo\": \"Prato Principal\", \"valor\": 18.00},\n",
        "    5: {\"nome\": \"Suco\", \"tipo\": \"Bebida\", \"valor\": 5.00},\n",
        "    6: {\"nome\": \"Refrigerante\", \"tipo\": \"Bebida\", \"valor\": 4.00},\n",
        "    7: {\"nome\": \"Água\", \"tipo\": \"Bebida\", \"valor\": 2.50},\n",
        "    8: {\"nome\": \"Pudim\", \"tipo\": \"Sobremesa\", \"valor\": 6.00},\n",
        "    9: {\"nome\": \"Doce de Maracujá\", \"tipo\": \"Sobremesa\", \"valor\": 5.50},\n",
        "    10: {\"nome\": \"Bolo de Chocolate\", \"tipo\": \"Sobremesa\", \"valor\": 7.00}\n",
        "}\n",
        "\n",
        "\n",
        "# Variável de controle para determinar a etapa do fluxo\n",
        "etapa = 1  # Começa na etapa 1 (ver cardápio)\n",
        "tamanho = \"p\"  # Tamanho padrão da marmita (pequena)\n",
        "\n",
        "# Lista para armazenar os itens do pedido do cliente\n",
        "itens_cliente = []\n",
        "\n",
        "\n",
        "# Função para criar um item do pedido\n",
        "def criar_item(nome, tipo, valor, quantidade=1):\n",
        "    return {'nome': nome, 'tipo': tipo, 'valor': valor, 'quantidade': quantidade, 'valor_final': valor * quantidade}\n",
        "\n",
        "\n",
        "# Função para adicionar itens ao pedido com base no texto do usuário\n",
        "def adicionar_itens_nomes(texto_usuario):\n",
        "    itens_encontrados = []\n",
        "    for item_id, item_info in menu.items():\n",
        "        if item_info['nome'].lower() in texto_usuario:  # Verifica se o nome do item está no texto\n",
        "            item = criar_item(item_info['nome'], item_info['tipo'], item_info['valor'])\n",
        "            itens_cliente.append(item)  # Adiciona o item ao pedido\n",
        "            itens_encontrados.append(item_info['nome'])  # Salva o nome do item encontrado\n",
        "    return itens_encontrados\n",
        "\n",
        "\n",
        "# Função para calcular o preço total do pedido\n",
        "def calcular_preco():\n",
        "    return sum(item['valor_final'] for item in itens_cliente)\n",
        "\n",
        "\n",
        "# Função para aplicar ajuste de preço com base no tamanho da marmita\n",
        "def verifica_tamanho(preco, tamanho):\n",
        "    tamanhos_validos = {\"g\": 1.25, \"m\": 1.15, \"p\": 1.05}  # Fatores de ajuste para cada tamanho\n",
        "    return preco * tamanhos_validos.get(tamanho.lower(), 1)\n",
        "\n",
        "print(verifica_tamanho(10, \"g\"))\n",
        "print(verifica_tamanho(10, \"m\"))\n",
        "print(verifica_tamanho(10, \"p\"))\n",
        "print(verifica_tamanho(10, \"amfdakofnja\"))\n",
        "\n",
        "\n",
        "\n",
        "# Função para remover um item do pedido\n",
        "def remover_item(nome_item):\n",
        "    global itens_cliente\n",
        "    itens_cliente = [item for item in itens_cliente if item['nome'].lower() != nome_item.lower()]  # Remove o item pelo nome\n",
        "    resumo_atualizado = resumo_pedido()\n",
        "    novo_total = calcular_preco()\n",
        "    return (f\"Item '{nome_item}' foi removido do seu pedido.\\n\"\n",
        "            f\"{resumo_atualizado}\\n\"\n",
        "            f\"Novo total do pedido: R${novo_total:.2f}.\")\n",
        "\n",
        "\n",
        "# Função para exibir o resumo do pedido\n",
        "def resumo_pedido():\n",
        "    if not itens_cliente:  # Verifica se a lista está vazia\n",
        "        return \"Seu pedido está vazio no momento.\"\n",
        "    return \"Aqui está o resumo do seu pedido:\\n\" + \"\\n\".join(\n",
        "        [f\"{item['nome']} custa R${item['valor']:.2f}\" for item in itens_cliente]\n",
        "    )\n",
        "\n",
        "\n",
        "# Função para converter texto em áudio e salvar no disco\n",
        "def texto_para_voz(texto, file_path=\"resposta.mp3\"):\n",
        "    if not texto:  # Retorna None se o texto estiver vazio\n",
        "        return None\n",
        "    tts = gTTS(text=texto, lang='pt')  # Converte o texto em áudio\n",
        "    tts.save(file_path)\n",
        "    return file_path\n",
        "\n",
        "# Função para lidar com mensagens de voz recebidas pelo bot\n",
        "@bot.message_handler(content_types=['voice'])\n",
        "def handle_voice_message(message):\n",
        "    global etapa, tamanho  # Referência global para as variáveis de etapa e tamanho\n",
        "    file_info = bot.get_file(message.voice.file_id)  # Obtém informações sobre o arquivo de áudio\n",
        "    file = bot.download_file(file_info.file_path)  # Faz o download do áudio\n",
        "\n",
        "    # Salva o arquivo de áudio em um diretório local\n",
        "    audio_path = os.path.join(AUDIO_DIR, f\"{message.voice.file_id}.ogg\")\n",
        "    with open(audio_path, 'wb') as f:\n",
        "        f.write(file)\n",
        "\n",
        "    # Transcreve o áudio usando Whisper com o idioma português\n",
        "    result = model.transcribe(audio_path, language=\"pt\")\n",
        "    texto_usuario = result['text'].lower()\n",
        "    transcricao = f\"MENSAGEM DO USUÁRIO: {texto_usuario}\\n\"\n",
        "\n",
        "    # Variável para armazenar a resposta do bot\n",
        "    resposta = \"\"\n",
        "\n",
        "    # Opção de voltar para a etapa anterior\n",
        "    if \"voltar\" in texto_usuario:\n",
        "        etapa = max(1, etapa - 1)  # Garante que a etapa não seja menor que 1\n",
        "        resposta = f\"Você voltou para a etapa {etapa}. Vamos reiniciar essa etapa.\"\n",
        "        transcricao += f\"MENSAGEM DO BOT: Voltando para a etapa {etapa}.\\n\"\n",
        "\n",
        "    # Controle de etapas\n",
        "    if etapa == 1:  # Etapa 1 - Ver o cardápio\n",
        "        resposta += \"Bem-vindo à etapa 1: Visualizar o cardápio.\\n\"\n",
        "        if \"cardápio\" in texto_usuario or \"menu\" in texto_usuario:\n",
        "            resposta += \"Aqui está o nosso cardápio:\\n\" + \"\\n\".join(\n",
        "                [f\"{k}. {v['nome']} - R${v['valor']}\" for k, v in menu.items()]\n",
        "            )\n",
        "            transcricao += \"MENSAGEM DO BOT: Mostrando o cardápio.\\n\"\n",
        "            etapa = 2  # Avança para a próxima etapa\n",
        "            resposta += \"\\nAgora, escolha os itens do seu pedido falando o nome dos itens.\"\n",
        "        else:\n",
        "            resposta += \"Por favor, peça para ver o cardápio para começar.\"\n",
        "\n",
        "    elif etapa == 2:  # Etapa 2 - Fazer pedido\n",
        "        resposta += \"Estamos na etapa 2: Escolher os itens do pedido.\\n\"\n",
        "        if \"gostaria\" in texto_usuario or \"quero\" in texto_usuario:\n",
        "            itens_adicionados = adicionar_itens_nomes(texto_usuario)\n",
        "            if itens_adicionados:\n",
        "                resposta += f\"Itens adicionados ao seu pedido: {', '.join(itens_adicionados)}.\"\n",
        "                transcricao += f\"MENSAGEM DO BOT: Itens {', '.join(itens_adicionados)} adicionados ao pedido.\\n\"\n",
        "                etapa = 3  # Avança para a próxima etapa\n",
        "                resposta += \"\\nPara ver, adicionar ou remover itens do pedido, diga 'ver pedido' ou 'remover'.\"\n",
        "            else:\n",
        "                resposta += \"Não encontrei o item solicitado no cardápio. Verifique o nome e tente novamente.\"\n",
        "        else:\n",
        "            resposta += \"Escolha os itens que deseja pedir dizendo o nome deles.\"\n",
        "\n",
        "    elif etapa == 3:  # Etapa 3 - Ver pedido, remover ou adicionar\n",
        "        resposta += \"Estamos na etapa 3: Ajustar o pedido.\\n\"\n",
        "        if \"ver pedido\" in texto_usuario or \"resumo\" in texto_usuario:\n",
        "            resposta += resumo_pedido()\n",
        "            transcricao += \"MENSAGEM DO BOT: Exibindo o resumo do pedido.\\n\"\n",
        "            resposta += \"\\nVocê pode adicionar mais itens ou remover algum dizendo 'remover [nome do item]'. Quando estiver satisfeito, diga 'avançar' para continuar.\"\n",
        "\n",
        "        elif \"remover\" in texto_usuario:\n",
        "            nome_item = texto_usuario.split(\"remover\", 1)[1].strip()  # Extrai o nome do item para remover\n",
        "            resposta += remover_item(nome_item)\n",
        "            transcricao += f\"MENSAGEM DO BOT: {resposta}\\n\"\n",
        "\n",
        "        elif \"avançar\" in texto_usuario:\n",
        "            etapa = 4  # Avança para a etapa seguinte\n",
        "            resposta += \"Agora, escolha o tamanho da marmita dizendo 'grande', 'médio' ou 'pequeno'.\"\n",
        "\n",
        "    elif etapa == 4:  # Etapa 4 - Informar tamanho da marmita\n",
        "        resposta += \"Estamos na etapa 4: Escolher o tamanho da marmita.\\n\"\n",
        "        if \"grande\" in texto_usuario or \"medio\" in texto_usuario or \"pequeno\" in texto_usuario:\n",
        "            tamanho = next((palavra[0].lower() for palavra in [\"grande\", \"medio\", \"pequena\"] if palavra in texto_usuario), \"p\")\n",
        "            resposta += f\"Tamanho da marmita ajustado para {tamanho.upper()}.\"\n",
        "            transcricao += f\"MENSAGEM DO BOT: Tamanho ajustado para {tamanho.upper()}.\\n\"\n",
        "            etapa = 5  # Avança para a próxima etapa\n",
        "            resposta += \"\\nPor favor, informe o endereço de entrega.\"\n",
        "        else:\n",
        "            resposta += \"Escolha o tamanho da marmita dizendo 'grande', 'médio' ou 'pequeno'.\"\n",
        "\n",
        "    elif etapa == 5:  # Etapa 5 - Finalizar pedido com endereço e valor total\n",
        "        resposta += \"Estamos na etapa 5: Informar endereço.\\n\"\n",
        "        preco_total = calcular_preco()  # Calcula o valor base do pedido\n",
        "        preco_final = verifica_tamanho(preco_total, tamanho)  # Aplica o ajuste pelo tamanho da marmita\n",
        "        resposta += (f\"Endereço recebido: {texto_usuario}.\\n\"\n",
        "                     f\"O valor total do pedido é R${preco_final:.2f}.\\n\"\n",
        "                     f\"Obrigado pelo pedido! Aguarde o nosso contato para mais detalhes.\")\n",
        "        transcricao += (f\"MENSAGEM DO BOT: Endereço registrado: {texto_usuario}.\\n\"\n",
        "                        f\"Valor final do pedido: R${preco_final:.2f}.\\n\")\n",
        "        etapa = 1  # Reinicia o processo para um novo pedido\n",
        "\n",
        "    # Enviar transcrição e resposta em áudio\n",
        "    bot.send_message(message.chat.id, transcricao)\n",
        "\n",
        "    # Converter resposta em áudio e enviar\n",
        "    if resposta:\n",
        "        resposta_audio = texto_para_voz(resposta)\n",
        "        if resposta_audio:\n",
        "            with open(resposta_audio, 'rb') as audio:\n",
        "                bot.send_voice(message.chat.id, audio)\n",
        "\n",
        "# Inicia o bot e aguarda mensagens\n",
        "bot.polling()"
      ]
    }
  ]
}
